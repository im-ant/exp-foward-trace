#!/bin/bash

# ============================================================================
# Script submitted to sbatch to run a hydra parameter sweep on the cluster
#
# Author: Anthony G. Chen
# ============================================================================

# Format for where to put the parameter sweep outputs
sweep_parent_dir='/network/tmp1/chenant/ant/sr_trace/${now:%Y-%m-%d}/${now:%H-%M-%S}'

# ===========================
# Experimental set-up

# (1.1) Load packages
module load python/3.7
module load python/3.7/cuda/10.1/cudnn/7.6/pytorch/1.5.0

# (1.2) Load environment
source $HOME/venvs/rlpyt/bin/activate

# (2) no data to copy

# (3) launch job with parameter sweeps
python -u train_incremental.py --multirun \
    hydra.run.dir=$sweep_parent_dir \
    hydra.sweep.dir=$sweep_parent_dir \
    runner.n_steps=1e6 \
    runner.kwargs.log_interval_episodes=100 \
    env.kwargs.env_name='breakout' \
    algo.cls_string='ACLambda' \
    algo.kwargs.lr_alpha=0.00048828125 \
    algo.kwargs.trace_lambda=0.0,0.8 \
    model.cls_string='ACNetwork' \
    model.kwargs.fc_sizes=128 \
    training.seed=2,4 \

# (4) Copy things over to scratch?
# cp $EXP_LOG_PATH /network/tmp1/chenant/tmp/
