#!/bin/bash

# ============================================================================
# Script submitted to sbatch to run a hydra parameter sweep on the cluster
#
# Author: Anthony G. Chen
# ============================================================================

# Format for where to put the parameter sweep outputs
sweep_parent_dir='/network/tmp1/chenant/ant/sr_trace/${now:%Y-%m-%d}/${now:%H-%M-%S}'

# ===========================
# Experimental set-up

# (1.1) Load packages
module load python/3.7
module load python/3.7/cuda/10.1/cudnn/7.6/pytorch/1.5.0

# (1.2) Load environment
source $HOME/venvs/rlpyt/bin/activate

# (2) no data to copy

# (3) launch job with parameter sweeps
#python -u train_linear_prediction.py --multirun \
python -u train_linear_prediction.py \
    hydra.run.dir=$sweep_parent_dir \
    hydra.sweep.dir=$sweep_parent_dir \
    training.num_episodes=1000 \
    training.seed=[2,4,6,8,10,12,14,16,18,20] \
    env.cls_string="PerfBinaryTreeEnv" \
    +env.kwargs.depth=[3,5,7] \
    agent=sf_return \
    agent.kwargs.lr=[0.001,0.01,0.03,0.06,0.1] \
    agent.kwargs.gamma=0.9 \
    agent.kwargs.lamb=[0.0,0.3,0.5,0.7,0.9,0.99,1.0] \
    agent.kwargs.eta_trace=[0.0,0.3,0.5,0.7,0.9,0.99,1.0] \
    agent.kwargs.use_true_sf_params=[True,False] \
    agent.kwargs.use_true_reward_params=[True,False] \

# (4) Copy things over to scratch?
# cp $EXP_LOG_PATH /network/tmp1/chenant/tmp/
